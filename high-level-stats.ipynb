{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "import csv\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "column_names = []\r\n",
    "column_matrix = None\r\n",
    "num_of_columns = 0\r\n",
    "column_dtype = None\r\n",
    "datatype = {0:\"int\",1:\"float\",2:\"object\"}"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "def csv_reader(filename,sep=','):\r\n",
    "    #Exception handling for types and file not found errors.\r\n",
    "    try:\r\n",
    "        with open(filename,'r') as csvreader:\r\n",
    "            csv_file = np.genfromtxt((csvreader),invalid_raise=False, dtype=None,delimiter=sep,encoding=None,skip_header=0)\r\n",
    "        a= iter(csv_file)\r\n",
    "        headers = next(a)\r\n",
    "        return csv_file\r\n",
    "    except FileNotFoundError as e:\r\n",
    "        print(e)\r\n",
    "    except TypeError as t:\r\n",
    "        print(t)\r\n",
    "    except UnboundLocalError as f:\r\n",
    "        print(f)\r\n",
    "    except Exception as e:\r\n",
    "        print(e)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Returns data matrix\r\n",
    "def get_data_matrix():\r\n",
    "    return column_matrix"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# All statistics functions\r\n",
    "def get_min(col):\r\n",
    "    return np.min(col)\r\n",
    "    \r\n",
    "def get_max(col):\r\n",
    "    return np.max(col)\r\n",
    "\r\n",
    "def get_count(col):\r\n",
    "    return col.size\r\n",
    "\r\n",
    "def get_std(col):\r\n",
    "    return round(np.std(col))\r\n",
    "\r\n",
    "def get_Q1(col):\r\n",
    "    q1=np.quantile(col,.25)\r\n",
    "    return round(q1)\r\n",
    "    \r\n",
    "def get_Q2(col):\r\n",
    "    q2=np.quantile(col,.50)\r\n",
    "    return round(q2)\r\n",
    "\r\n",
    "def get_Q3(col):\r\n",
    "    q3=np.percentile(col,.75)\r\n",
    "    return round(q3)\r\n",
    "\r\n",
    "def get_unique(col):\r\n",
    "    return np.unique(col)[1]\r\n",
    "\r\n",
    "# Partially code copied from https://stackoverflow.com/questions/19909167/how-to-find-most-frequent-string-element-in-numpy-ndarray\r\n",
    "def get_top(col):\r\n",
    "    unique,pos = np.unique(col,return_inverse=True) #Finds all unique elements and their positions\r\n",
    "    counts = np.bincount(pos)                     #Count the number of each unique element\r\n",
    "    maxpos = counts.argmax()  \r\n",
    "    return col[maxpos]\r\n",
    "\r\n",
    "def outlier_percent(col):\r\n",
    "    #Logic is to find the upper and lower limit and check how many fall into the range and calculate the percentage of those that don't.\r\n",
    "    q1=get_Q1(col)\r\n",
    "    q3 = get_Q3(col)\r\n",
    "    out_range=[]\r\n",
    "    iqr= abs(q3-q1)\r\n",
    "    lower_limit = abs(q1-(1.5*iqr))\r\n",
    "    upper_limit = abs(q3+(1.5*iqr))\r\n",
    "    #Handling error for 0 division.\r\n",
    "    try:\r\n",
    "        for i in col:\r\n",
    "            if i>upper_limit or i<lower_limit: #Checking if it is out of the upper and lower limit.\r\n",
    "                out_range.append(i)\r\n",
    "        outlier_per  = (len(out_range)/len(col))*100\r\n",
    "        return outlier_per\r\n",
    "    except ZeroDivisionError:\r\n",
    "        return print(\"No outliers\")\r\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Returns high-level statistics of categorical columns\r\n",
    "def get_stat_categorical(idx):\r\n",
    "    stat_dict = {}\r\n",
    "    matrix =  get_data_matrix()\r\n",
    "    processed_column = np.array([])\r\n",
    "    \r\n",
    "    for val in matrix[:,idx]:\r\n",
    "        if val != '':\r\n",
    "            processed_column = np.append(processed_column,(val))\r\n",
    "            \r\n",
    "    stat_dict[\"min\"] = np.NaN\r\n",
    "    stat_dict[\"max\"] = np.NaN\r\n",
    "    stat_dict[\"count\"] = get_count(processed_column)\r\n",
    "    stat_dict[\"std\"] = np.NaN\r\n",
    "    stat_dict[\"Q1\"] = np.NaN\r\n",
    "    stat_dict[\"Q2\"] = np.NaN\r\n",
    "    stat_dict[\"Q3\"] = np.NaN\r\n",
    "    stat_dict[\"Unique\"] = get_unique(processed_column)\r\n",
    "    stat_dict[\"Top\"] = get_top(processed_column)\r\n",
    "    stat_dict[\"OP\"] = np.NaN\r\n",
    "#     print(\"-------------------\")\r\n",
    "#     print(\"Processed categorical:\",stat_dict)\r\n",
    "    return stat_dict"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Returns high-level statistics of numerical columns\r\n",
    "def get_stat_numeric(idx):\r\n",
    "    stat_dict = {}\r\n",
    "    matrix =  get_data_matrix()\r\n",
    "    processed_column = np.array([])\r\n",
    "   \r\n",
    "    if column_dtype[idx] == 0:\r\n",
    "        # column is int type\r\n",
    "        for val in matrix[:,idx]:\r\n",
    "            if val != '':\r\n",
    "                processed_column = np.append(processed_column, int(val))\r\n",
    "#         print(\"-------------------\")\r\n",
    "#         print(\"Processed int:\",processed_column)\r\n",
    "    else:\r\n",
    "        \r\n",
    "        # column is float type\r\n",
    "        for val in matrix[:,idx]:\r\n",
    "            if val != '':\r\n",
    "                processed_column = np.append(processed_column, float(val))\r\n",
    "#         print(\"-------------------\")\r\n",
    "#         print(\"Processed float:\",processed_column)\r\n",
    "                \r\n",
    "    stat_dict[\"min\"] = get_min(processed_column)\r\n",
    "    stat_dict[\"max\"] = get_max(processed_column)\r\n",
    "    stat_dict[\"count\"] = get_count(processed_column)\r\n",
    "    stat_dict[\"std\"] = get_std(processed_column)\r\n",
    "    stat_dict[\"Q1\"] = get_Q1(processed_column)\r\n",
    "    stat_dict[\"Q2\"] = get_Q2(processed_column)\r\n",
    "    stat_dict[\"Q3\"] = get_Q3(processed_column)\r\n",
    "    stat_dict[\"Unique\"] = np.NaN\r\n",
    "    stat_dict[\"Top\"] = np.NaN\r\n",
    "    stat_dict[\"OP\"] = outlier_percent(processed_column)\r\n",
    "        \r\n",
    "#     print(stat_dict)\r\n",
    "    return stat_dict"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# Return high-level statistics e.g. min,max,count etc\r\n",
    "def get_statistics():\r\n",
    "    stats ={}\r\n",
    "    # check data type for each columns\r\n",
    "    for idx,col_name in enumerate(column_names):\r\n",
    "        if column_dtype[idx] in [0,1]:\r\n",
    "            # We have numeric column type\r\n",
    "            stats[col_name] = get_stat_numeric(idx)\r\n",
    "        else:\r\n",
    "            # We have object column type\r\n",
    "            stats[col_name] = get_stat_categorical(idx)\r\n",
    "            \r\n",
    "#     print(\"-------------------\")\r\n",
    "#     print(\"final stats : \",stats)   \r\n",
    "    return stats"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Checks data types Return 0 for int, 1 for float and 2 for object\r\n",
    "def check_dtypes(value):\r\n",
    "    if not value:\r\n",
    "        return 0\r\n",
    "    try:\r\n",
    "        # Convert it into integer\r\n",
    "        val = int(value)\r\n",
    "        # We have integer type\r\n",
    "        return 0\r\n",
    "    except ValueError:\r\n",
    "        try:\r\n",
    "            # Convert it into float\r\n",
    "            val = float(value)\r\n",
    "            # We have float type\r\n",
    "            return 1\r\n",
    "        except ValueError:\r\n",
    "            # We have object type \r\n",
    "            return 2"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Calculate datatype for each columns\r\n",
    "def calculate_dtype():\r\n",
    "    for col in range(num_of_columns):\r\n",
    "        current_column = column_matrix[1:,col]\r\n",
    "        # Loop through each value of a column\r\n",
    "        for val in current_column:\r\n",
    "            datatype = check_dtypes(val)\r\n",
    "            column_dtype[col] = max(column_dtype[col],datatype)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# Partial code used from https://towardsdatascience.com/simple-little-tables-with-matplotlib-9780ef5d0bc4\r\n",
    "def plot_stats(stats):\r\n",
    "    stat_names = [\"min\",\"max\",\"count\",\"std\",\"Q1\",\"Q2\",\"Q3\",\"Unique\",\"Top\",\"OP\"] \r\n",
    "    feature_names = [] \r\n",
    "    data = [] \r\n",
    "\r\n",
    "    for feature, value in stats.items():\r\n",
    "        feature_names.append(feature)\r\n",
    "        row =[]\r\n",
    "        for stat_name in stat_names:\r\n",
    "            row.append(value[stat_name])\r\n",
    "        data.append(row)\r\n",
    "\r\n",
    "#     print(\"data:\",data)\r\n",
    "    title_text = 'Statistics Table'\r\n",
    "    print(title_text)\r\n",
    "\r\n",
    "    # Get some lists of color specs for row and column headers\r\n",
    "    rcolors = plt.cm.BuPu(np.full(len(feature_names), 0.1))\r\n",
    "    ccolors = plt.cm.BuPu(np.full(len(stat_names), 0.1))\r\n",
    "    # Create the figure. Setting a small pad on tight_layout\r\n",
    "    # seems to better regulate white space. Sometimes experimenting\r\n",
    "    # with an explicit figsize here can produce better outcome.\r\n",
    "    plt.figure(linewidth=4,\r\n",
    "               tight_layout={'pad':1},\r\n",
    "          )\r\n",
    "    # Add a table at the bottom of the axes\r\n",
    "    the_table = plt.table(cellText=data,\r\n",
    "                          rowLabels=feature_names,\r\n",
    "                          rowColours=rcolors,\r\n",
    "                          rowLoc='right',\r\n",
    "                          colColours=ccolors,\r\n",
    "                          colLabels=stat_names,\r\n",
    "                          loc='center')\r\n",
    "    # Scaling is the only influence we have over top and bottom cell padding.\r\n",
    "    # Make the rows taller (i.e., make cell y scale larger).\r\n",
    "    the_table.scale(4, 4.5)\r\n",
    "    # Hide axes\r\n",
    "    ax = plt.gca()\r\n",
    "    ax.get_xaxis().set_visible(False)\r\n",
    "    ax.get_yaxis().set_visible(False)\r\n",
    "    # Hide axes border\r\n",
    "    plt.box(on=None)\r\n",
    "    # Add title\r\n",
    "#     plt.suptitle(title_text)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "if __name__ == \"__main__\":\r\n",
    "    file = csv_reader('data/Latest_Covid_India.csv')\r\n",
    "    # Get column names\r\n",
    "    column_names = file[0,:]\r\n",
    "    # Caculate length of columns\r\n",
    "    num_of_columns = len(column_names)\r\n",
    "    # Initialize column data types to zero\r\n",
    "    column_dtype = np.zeros(num_of_columns)\r\n",
    "    # Get data except column names\r\n",
    "    column_matrix = file[1:,:]             \r\n",
    "    \r\n",
    "    # Calculate data types for each columns\r\n",
    "    calculate_dtype()            \r\n",
    "    # Return high level stats of each columns\r\n",
    "    stats = get_statistics()\r\n",
    "    \r\n",
    "#     print(\"stats:\",stats)\r\n",
    "    plot_stats(stats)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26680/3481751251.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mcalculate_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Return high level stats of each columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#     print(\"stats:\",stats)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26680/739191581.py\u001b[0m in \u001b[0;36mget_statistics\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcolumn_dtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m# We have numeric column type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_stat_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;31m# We have object column type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26680/4017872600.py\u001b[0m in \u001b[0;36mget_stat_numeric\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mstat_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Unique\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mstat_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Top\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mstat_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"OP\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutlier_percent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m#     print(stat_dict)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26680/3843649618.py\u001b[0m in \u001b[0;36moutlier_percent\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mout_range\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0moutlier_per\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutlier_per\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No outliers\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "734bbb5c9c99cdc2e878e5e6244183c0954578259d9deecf0a29ecf5cb3f2511"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}